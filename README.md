# ğŸ” Local Research Agent (Async, Free, Ollama-Powered)

A **fully local, free, async research agent** that searches the web, scrapes sources, detects contradictions, scores factual confidence, and produces structured research reports â€” powered by **Ollama** and open-source tooling.

Designed for **deep technical and scientific research**, not shallow summaries.

---

## âœ¨ Features

- âœ… Local LLMs via Ollama (no cloud, no paid APIs)
- âš¡ Async web search & scraping (3â€“5Ã— faster)
- ğŸ§  Query planning agent
- ğŸ“„ Multi-source research synthesis
- âš ï¸ Contradiction detection agent
- ğŸ“Š Fact confidence scoring
- ğŸ›¡ï¸ Robust JSON handling & self-healing
- ğŸ“ Markdown + JSON outputs
- ğŸ”Œ Model-agnostic (Qwen, LLaMA, etc.)

---

## ğŸ§  Recommended Models

| Task | Model |
|---|---|
| Query planning | llama3.2:1b |
| Contradiction detection | llama3.2:1b |
| Final synthesis | qwen2.5:7b |

> âš ï¸ Small models (1B) are **not suitable** for deep physics or math-heavy synthesis (e.g. Bellâ€™s theorem). Use them only for planning or classification.

---

## ğŸ“ Project Structure

```
research_agent/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ planner.py
â”‚   â”œâ”€â”€ async_search.py
â”‚   â”œâ”€â”€ async_scraper.py
â”‚   â”œâ”€â”€ cleaner.py
â”‚   â”œâ”€â”€ synthesizer.py
â”‚   â”œâ”€â”€ contradiction.py
â”‚   â””â”€â”€ confidence.py
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ ollama_client.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ report.md
â”‚   â””â”€â”€ facts.json
â”‚
â”œâ”€â”€ async_run.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Install & run Ollama

```bash
ollama pull qwen2.5:7b
ollama pull llama3.2:1b
ollama serve
```

If Ollama runs on another machine:

```bash
export OLLAMA_HOST=http://<OLLAMA_IP>:11434
```

---

### 3ï¸âƒ£ Run the research agent

```bash
MODEL=qwen2.5:7b python async_run.py
```

Example input:

```
Research topic: bell's theorem
```

Outputs:
- `outputs/report.md`
- `outputs/facts.json`

---

## ğŸ§ª Example Output

### Fact (JSON)

```json
{
  "claim": "Bell's theorem shows that no local hidden variable theory can reproduce all predictions of quantum mechanics",
  "source": "https://...",
  "confidence": 0.91
}
```

---

## ğŸ›¡ï¸ Reliability & Safety

This project is designed to **not crash** when LLMs misbehave:

- Invalid JSON â†’ auto-repair
- Empty responses â†’ fallback paths
- Token overflow â†’ context caps
- Weak models â†’ graceful degradation

---

## âš ï¸ Known Limitations

- DuckDuckGo results may vary by region
- Heavy math / LaTeX content is summarized, not derived
- No Google scraping (by design)
- No formal peer-review verification

---

## ğŸ”® Planned Enhancements

- Citation graph (fact â†’ multiple sources)
- Math-aware parsing (LaTeX blocks)
- SQLite research cache
- RAG memory (Chroma / FAISS)
- Streamlit â€œResearch Copilotâ€ UI
- CLI flags (`--deep`, `--fast`, `--physics`)

---

## ğŸ“œ Philosophy

> **Research should be transparent, local, auditable, and reproducible.**

This project favors:
- Open models
- Open web
- Explicit uncertainty
- Human-readable outputs

---

## ğŸ“„ License

MIT License
